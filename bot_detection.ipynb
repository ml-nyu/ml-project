{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Twitter Bot Detection using Random Forest and Naive Bayes classifier\n",
    "             Project By : Girish Ganesh Prabhu (rrk310) and Rahul Ramesh Kumar (rrk310)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Open Training File\n",
    "import json\n",
    "arr = []\n",
    "\n",
    "with open('training/twitter_features_training.json') as data_file:\n",
    "    randomdata = json.load(data_file)\n",
    "    arr = randomdata['k']\n",
    "rows = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        Clean data and extract new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favourites</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>verified</th>\n",
       "      <th>desc</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1016</td>\n",
       "      <td>249</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2144</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>5</td>\n",
       "      <td>1786</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>1</td>\n",
       "      <td>95162</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      favourites  followers  friends  verified  desc  totaltweets  \\\n",
       "1086           0         16        2         0     0         7543   \n",
       "1486        1016        249      405         0     0         2144   \n",
       "355            5       1786       43         0     1          392   \n",
       "1333           1      95162       43         1     0            1   \n",
       "182            2         23        0         0     0           99   \n",
       "\n",
       "      in_reply_to_status_id  is_quote_status  listed_count  bot  \n",
       "1086                      0                0            15    1  \n",
       "1486                     21               37             3    0  \n",
       "355                       0                0            88    1  \n",
       "1333                      0                0          1143    0  \n",
       "182                      87                0             1    1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from __future__ import division\n",
    "import collections\n",
    "\n",
    "hint = 'bot'\n",
    "\n",
    "column_headers = [ 'favourites' , 'default_profile',  \\\n",
    "                  'followers' , 'friends'  , \\\n",
    "                  'verified' , \\\n",
    "                  'default_profile_image' , 'name_hint' ,  \\\n",
    "                  'name' , 'screenname' , 'description' , \\\n",
    "                  'has_extended_profile', 'location' ,'desc' ,  \\\n",
    "                  'totaltweets', 'loc', 'in_reply_to_status_id', \\\n",
    "                  'socialness', 'is_quote_status' , 'diversity' , \\\n",
    "                  'listed_count' , 'avgurls', 'avghashtags' ,'bot' ]\n",
    "\n",
    "index = collections.OrderedDict()\n",
    "\n",
    "#Fill a map with header to index\n",
    "for i in range(0,len(column_headers)):\n",
    "    index[column_headers[i]] = i\n",
    "\n",
    "# get hint from name\n",
    "def get_name_hint(s):\n",
    "    if s is 0 :\n",
    "        return 0\n",
    "    return 1 if hint in s.lower().split() else 0\n",
    "\n",
    "# get the diversity of characters\n",
    "def lexical_diversity(text):\n",
    "    diversity = 0\n",
    "    if len(text) == 0:\n",
    "        diversity =0\n",
    "    else:\n",
    "        diversity  = float(len(set(text))) / len(text)\n",
    "    return round(diversity,2)\n",
    "\n",
    "#calculates the lexical diversity for a user\n",
    "def return_diversity(v):\n",
    "    tot_div =0\n",
    "    sz =0\n",
    "    for key,value in v.items():\n",
    "        if key == 'tweets':\n",
    "            sz = sz+1\n",
    "            for tweet in value:\n",
    "                tw = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",tweet).split())\n",
    "                tot_div = tot_div + lexical_diversity(tw)\n",
    "    \n",
    "    if(sz != 0) :\n",
    "        tot_div = tot_div/sz\n",
    "    return tot_div\n",
    "\n",
    "def get_diversity(row, v):\n",
    "    row[index['diversity']] = return_diversity(v)\n",
    "\n",
    "def get_desc_val(s):\n",
    "    if s is 0:\n",
    "        return 0\n",
    "    if hint in s.lower():\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def name_heuristic(name,desc):\n",
    "    return name or desc\n",
    "\n",
    "def digitize_loc(loc):\n",
    "    if loc is 0:\n",
    "        return 0\n",
    "    if len(loc.strip()) >0 :\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "#need to trim after getting all the derived features\n",
    "def trim_frame(df):\n",
    "    del df['description']\n",
    "    del df['name']\n",
    "    del df['screenname']\n",
    "    del df['location']\n",
    "    del df['default_profile_image']\n",
    "    del df['default_profile']\n",
    "    del df['has_extended_profile']\n",
    "    del df['avghashtags']\n",
    "    del df['avgurls'] \n",
    "    del df['name_hint']\n",
    "    del df['loc']\n",
    "    #del df['followers']\n",
    "    del df['socialness']\n",
    "    #del df['is_quote_status']\n",
    "    del df['diversity']\n",
    "    \n",
    "finalrow = []\n",
    "\n",
    "def prep(df):\n",
    "    df['default_profile_image'].fillna(0)\n",
    "    df['description'].fillna('Empty Description')\n",
    "    pd.isnull(df.location).astype(int)\n",
    "    trim_frame(df)\n",
    "    \n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    \n",
    "#append rows to dataframe\n",
    "def append_rows_to_list(v):\n",
    "    row = [0]*len(column_headers)\n",
    "    #get_diversity(row,v)\n",
    "    \n",
    "    for key,value in v.items():\n",
    "        if key in index:\n",
    "            if key == 'name' or key == 'screenname':                \n",
    "                row[index['name_hint']] = get_name_hint(value) or row[index['name_hint']]\n",
    "            else :\n",
    "                row[index[key]] = value\n",
    "    \n",
    "    #row[index['name_hint']] = name_heuristic(row[index['name']], row[index['screenname']])\n",
    "    row[index['desc']] = get_desc_val(row[index['description']])\n",
    "    row[index['loc']] = digitize_loc(row[index['location']])\n",
    "    \n",
    "    return row\n",
    "\n",
    "for k,v in rows[0].items():\n",
    "    r = append_rows_to_list(v)\n",
    "    if r is not None:\n",
    "        finalrow.append(r)\n",
    "        \n",
    "df1 = pd.DataFrame(finalrow,columns=column_headers)\n",
    "df1 = df1.sample(frac=1) #randomize\n",
    "prep(df1)# todo call for test as well\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                             Open Test File and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favourites</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>verified</th>\n",
       "      <th>desc</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1639</td>\n",
       "      <td>4535</td>\n",
       "      <td>1308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3061</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304</td>\n",
       "      <td>298</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>629</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13033</td>\n",
       "      <td>1046703</td>\n",
       "      <td>3018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3339</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1150</td>\n",
       "      <td>468</td>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213</td>\n",
       "      <td>191</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>696284</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favourites  followers  friends  verified  desc  totaltweets  \\\n",
       "0        1639       4535     1308         1     0         3061   \n",
       "1         304        298      780         0     0          629   \n",
       "2       13033    1046703     3018         1     0         3339   \n",
       "3        1150        468      522         0     0           66   \n",
       "4         213        191       68         0     1       696284   \n",
       "\n",
       "   in_reply_to_status_id  is_quote_status  listed_count  bot  \n",
       "0                     59               23           111  NaN  \n",
       "1                      3                6            10  NaN  \n",
       "2                      6                5           354  NaN  \n",
       "3                     23                2            18  NaN  \n",
       "4                    156                0            13  NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open Test File\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from __future__ import division\n",
    "\n",
    "rows = []\n",
    "with open('test/twitter_features_test.json') as data_file:\n",
    "    randomdata = json.load(data_file)\n",
    "    arr = randomdata['k']\n",
    "rows = arr\n",
    "finalrow = []\n",
    "\n",
    "cnt = 0\n",
    "for k,v in rows[0].items():\n",
    "    r = append_rows_to_list(v)\n",
    "    if r is not None:\n",
    "        finalrow.append(r)\n",
    "\n",
    "# create dataframe\n",
    "df2 = pd.DataFrame(finalrow,columns=column_headers)\n",
    "df2.apply(lambda row: (row['name'] or row['screenname']),axis=1)\n",
    "prep(df2)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                               Using Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR:  [ 0.          0.67837838  1.        ]\n",
      "FPR:  [ 0.          0.15631692  1.        ]\n",
      "AUC:  0.761030730945\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bot       0.77      0.84      0.80       467\n",
      "     nonbot       0.77      0.68      0.72       370\n",
      "\n",
      "avg / total       0.77      0.77      0.77       837\n",
      "\n",
      "Accuracy using Naive Bayes Classifier is  0.803925623498\n"
     ]
    }
   ],
   "source": [
    "#Using Bernoulli Naive Bayes\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "array = df1.values\n",
    "X = array[:,0:len(df1.columns)-1]\n",
    "Y = array[:, len(df1.columns)-1]\n",
    "X = X.astype(int)\n",
    "Y = Y.astype(int)\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "model = BernoulliNB()\n",
    "\n",
    "X = data_train\n",
    "Y = target_train\n",
    "\n",
    "scores =[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted_rf1 = model.predict(X_test)\n",
    "    target_names = ['bot', 'nonbot']\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predicted_rf1, pos_label=1)\n",
    "    scores.append(metrics.auc(fpr, tpr))\n",
    "    \n",
    "model.fit(data_train, target_train)\n",
    "predicted_nb = model.predict(data_test)\n",
    "    \n",
    "# #AUC \n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(target_test, predicted_nb, pos_label=1)\n",
    "print('TPR: ',tpr)\n",
    "print('FPR: ',fpr)\n",
    "print('AUC: ',metrics.auc(fpr, tpr))\n",
    "\n",
    "#Precision, recall and F1\n",
    "target_names = ['bot', 'nonbot']\n",
    "print(classification_report(target_test, predicted_nb, target_names=target_names))\n",
    "print('Accuracy using Naive Bayes Classifier is ' , np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR:  [ 0.          0.91891892  1.        ]\n",
      "FPR:  [ 0.          0.07280514  1.        ]\n",
      "AUC:  0.923056889866\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bot       0.94      0.93      0.93       467\n",
      "     nonbot       0.91      0.92      0.91       370\n",
      "\n",
      "avg / total       0.92      0.92      0.92       837\n",
      "\n",
      "Accuracy using Random Forest Classifier is  0.906844596413\n"
     ]
    }
   ],
   "source": [
    "# Using Random Forest Classifier\n",
    "from pandas import DataFrame\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "array = df1.values\n",
    "X = array[:,0:len(df1.columns)-1]\n",
    "Y = array[:, len(df1.columns)-1]\n",
    "X = X.astype(int)\n",
    "Y = Y.astype(int)\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "num_trees = 200\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=num_trees , n_jobs=2, random_state = 42)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "X = data_train\n",
    "Y = target_train\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "scores =[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted_rf1 = model.predict(X_test)\n",
    "    target_names = ['bot', 'nonbot']\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predicted_rf1, pos_label=1)\n",
    "    score = metrics.auc(fpr, tpr)\n",
    "    scores.append(score)\n",
    "    \n",
    "#Fit the training set\n",
    "model.fit(data_train, target_train)\n",
    "predicted_rf = model.predict(data_test)\n",
    "\n",
    "# #AUC \n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(target_test, predicted_rf, pos_label=1)\n",
    "print('TPR: ',tpr)\n",
    "print('FPR: ',fpr)\n",
    "print('AUC: ',metrics.auc(fpr, tpr))\n",
    "\n",
    "#Precision, recall and F1\n",
    "target_names = ['bot', 'nonbot']\n",
    "print(classification_report(target_test, predicted_rf, target_names=target_names))\n",
    "\n",
    "print('Accuracy using Random Forest Classifier is ' , np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                Ranking Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 6 (0.211376)\n",
      "2. feature 3 (0.206861)\n",
      "3. feature 4 (0.120129)\n",
      "4. feature 5 (0.091028)\n",
      "5. feature 2 (0.083517)\n",
      "6. feature 1 (0.075468)\n",
      "7. feature 8 (0.075455)\n",
      "8. feature 0 (0.070666)\n",
      "9. feature 7 (0.065499)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c46b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['favourites' 'followers' 'friends' 'verified' 'desc' 'totaltweets'\n",
      " 'in_reply_to_status_id' 'is_quote_status' 'listed_count' 'bot']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "X = data_train\n",
    "y = target_train\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    \n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "print(df1.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    Classify Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "realarray = df2.values\n",
    "predicted_rf_real = model.predict(realarray[:,0:len(df2.columns)-1])\n",
    "np.savetxt(\"test_output/op.csv\", predicted_rf_real, header='bot' ,delimiter=\",\", comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
